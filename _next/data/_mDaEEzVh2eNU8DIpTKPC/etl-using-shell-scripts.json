{"pageProps":{"article":{"blog_id":"c4973cc3-3c29-4fcb-9651-5d921b02eed2","title":"ETL using shell scripts","short_description":"In this lab, we perform ETL (Extract, Transform, Load) using shell scripts. Learn to extract data from delimited files, transform text data with cut and tr, and load it into a PostgreSQL database. This hands-on approach will gain essential skills for automating data management and integration.","description":"<div id=\"content-0\"><h1>What is ETL?</h1><p><strong>ETL</strong> stands for <strong>Extract, Transform, Load</strong>. It is a crucial process in data management and integration, typically used in data warehousing and data analytics. Here's a brief overview:</p><ul><li><strong>Extract</strong>:</li><li class=\"ql-indent-1\">This step involves retrieving data from various sources such as databases, files, APIs, or other systems. The goal is to gather raw data for further processing.</li><li><strong>Transform</strong>:</li><li class=\"ql-indent-1\">Once the data is extracted, it often needs to be cleaned, formatted, and transformed to fit the desired structure or schema. This step may include filtering, sorting, aggregating, and converting data to ensure consistency and compatibility.</li><li><strong>Load</strong>:</li><li class=\"ql-indent-1\">The final step is to load the transformed data into a target system, such as a database, data warehouse, or data lake. This makes the data available for querying, analysis, and reporting.</li></ul><p><br></p><h1>ETL using Shell Scripts</h1><p>In this lab we will covering about read and extract data from various delimited thing using shell command. We'll understand how to handle file input, parse the data, and prepare it for further processing. Master the techniques for transforming text data using powerful shell utilities like tr command. and finally load the data to the database. in this lab we will use PostgreSQL. </p></div><div id=\"content-1\"><h1><strong>Exercise 1 - Extracting data using 'cut' command</strong></h1><h2>Extracting characters</h2><p></p></div><div id=\"content-2\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">echo \"database\" | cut -c1-4</code></pre></div><div id=\"content-4\"><p>You should get the string ‘data’ as output.</p><p>The command below shows how to extract 5th to 8th characters.</p></div><div id=\"content-5\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">echo \"database\" | cut -c5-8</code></pre></div><div id=\"content-6\"><p>You should get the string ‘base’ as output.</p><p>Non-contiguous characters can be extracted using the comma.</p></div><div id=\"content-7\"><h2>Extracting fields/columns</h2><p>We can extract a specific column/field from a delimited text file, by mentioning</p><ul><li>the delimiter using the&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">-d</code>&nbsp;option, or</li><li>the field number using the&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">-f</code>&nbsp;option.</li></ul><p>The /etc/passwd is a “:” delimited file.</p><p>The command below extracts usernames (the first field) from /etc/passwd.</p></div><div id=\"content-8\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">cut -d\":\" -f1 /etc/passwd</code></pre></div><div id=\"content-9\"><p></p></div><div id=\"content-10\"><img  style='width:600px; height:100%'src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fetl_using_shell_script_img_1.png?alt=media&token=7a3e427e-002d-4d12-875f-8f8160cc984d'/></div><div id=\"content-11\"><h1><strong>Exercise 2 - Transforming data using 'tr'</strong></h1></div><div id=\"content-12\"><h2>Translate from one character set to another</h2><p>The command below translates all lower case alphabets to upper case.</p></div><div id=\"content-13\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">echo \"Shell Scripting\" | tr \"[a-z]\" \"[A-Z]\" echo \"Shell Scripting\" | tr \"[:lower:]\" \"[:upper:]\" echo \"Shell Scripting\" | tr \"[A-Z]\" \"[a-z]\"</code></pre></div><div id=\"content-14\"><h1>Prepared the Database for the practice</h1><p>In this exercise we will create a table called&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">users</code>&nbsp;in the PostgreSQL database using PostgresSQL CLI. This table will hold the user account information.</p><p>The table&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">users</code>&nbsp;will have the following columns: uname, uid, home</p></div><div id=\"content-15\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">create table users(username varchar(50),userid int,homedirectory varchar(100));</code></pre></div><div id=\"content-17\"><h1>Create the Shell Script File</h1>touch csv2db.sh. Then Open the file in the editor. Copy and paste the following lines into the newly created file.</p></div><div id=\"content-18\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\"># This script # Extracts data from /etc/passwd file into a CSV file. # The csv data file contains the user name, user id and # home directory of each user account defined in /etc/passwd # Transforms the text delimiter from \":\" to \",\". # Loads the data from the CSV file into a table in PostgreSQL database.</code></pre></div><div id=\"content-19\"><p>We need to add lines of code to the script that will xtract user name (field 1), user id (field 3), and home directory path (field 6) from /etc/passwd file using the&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">cut</code>&nbsp;command. </p></div><div id=\"content-20\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">cut -d\":\" -f1,3,6 /etc/passwd</code></pre></div><div id=\"content-21\"><p>then run the script. -&gt; bash csv2db.sh</p></div><div id=\"content-22\"><p>let us change the last line of command so it not directly printed trough the terminal instead we will save the output to .txt file</p></div><div id=\"content-23\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">cut -d\":\" -f1,3,6 /etc/passwd &gt; extracted-data.txt</code></pre></div><div id=\"content-24\"><img style='width:720px; heigth:100%;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fetl_using_shell_script_img_2.png?alt=media&token=3b31b28f-40bf-4f3e-952a-4d0607d133c6'/></div><div id=\"content-25\"><p>The extracted columns are separated by the original “:” delimiter. You need to convert this into a “,” delimited file. Add the below lines at the end of the script and save the file.</p></div><div id=\"content-26\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">tr \":\" \",\" &lt; extracted-data.txt &gt; transformed-data.csv</code></pre></div><div id=\"content-27\"><p>Run the script and then it automatically save the .csv file to your system. you can read it from the terimnal by calling this command: cat transformed-data.csv</p></div><div id=\"content-29\"><h3>To load data from a shell script, you will use the&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">psql</code>&nbsp;client utility in a non-interactive manner. This is done by sending the database commands through a command pipeline to&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">psql</code>&nbsp;with the help of&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">echo</code>&nbsp;command.</h3><p><br></p></div><div id=\"content-30\"><p>PostgreSQL command to copy data from a CSV file to a table is&nbsp;<code style=\"background-color: transparent; color: rgb(255, 153, 0);\">COPY</code>.</p><p>The basic structure of the command which we will use in our script is</p></div><div id=\"content-31\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">COPY table_name FROM 'filename' DELIMITERS 'delimiter_character' FORMAT;</code></pre></div><div id=\"content-32\"><p></p></div><div id=\"content-33\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">echo \"\\c template1;\\COPY users FROM '/home/project/transformed-data.csv' DELIMITERS ',' CSV;\" | psql --username=postgres --host=localhost</code></pre></div><div id=\"content-34\"><pre style=\"background-color: black; color: white; padding:10px; border-radius: 5px;\"><code style=\"color: white;\">echo '\\c template1; \\\\SELECT * from users;' | psql --username=postgres --host=localhost</code></pre></div><div id=\"content-35\"><img style='width:720px; height:100%;' src='https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fetl_using_shell_script_img_3.png?alt=media&token=ff23b79e-4971-4f41-9060-58b47f009358'/></div>","timestamp":"Friday, September 20, 2024 at 11:36:39 AM GMT+8","image":"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fetl_using_shell_scripts.png?alt=media&token=e81bec9a-d988-429f-954c-eab34e3d0e11","image_alt":"ETL Using bash Script","slug":"etl-using-shell-scripts","index":"6b86b273ff34f","tags":["Data"]},"recommendedPosts":[{"blog_id":"19882a74-d1c2-4b31-837e-99cdc1846fcf","title":"Apache Cassandra: The NoSQL Powerhouse","short_description":"In today's world of big data, scalability and performance are crucial. Apache Cassandra, an open-source NoSQL database, is a top choice for handling large-scale, distributed data. Used by giants like Facebook, Netflix, and Twitter, Cassandra offers high availability, fault tolerance, and seamless scalability. Let’s dive into its architecture and key concepts!","timestamp":"2025-03-14 01:26:37","image":"https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1741944106846_apache_cassandra.png","image_alt":"Apache Cassandra","slug":"Apache-Cassandra-The-NoSQL-Powerhouse","index":"6b86b273ff34f","tags":["NO SQL","Data"]},{"blog_id":"6b4113f2-f30c-4e12-a34a-f5c02abbd1cb","title":"Mastering Apache Spark: An Engaging Dive into Its Architecture and Clusters","short_description":"Welcome to an in-depth exploration of Apache Spark’s architecture! Whether you’re new to Spark or looking to refresh your understanding, this interactive guide will walk you through the key concepts that power Spark’s ability to process massive datasets quickly and efficiently.","timestamp":"2024-10-06 21:37:09","image":"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fspark.png?alt=media&token=7a343f5c-0174-4a31-99e1-4943f9e135af","image_alt":"Apache Spark","slug":"mastering-apache-spark-an-engaging-dive-into-its-architecture-and-clusters","index":"6b86b273ff34f","tags":["Data","Software Architecture","System Design","Storage"]},{"blog_id":"9f224db5-a76d-4a6f-9f7b-32bfbdf5696f","title":"MapReduce: The Magic Behind Processing Big Data in Hadoop","short_description":"Ever wondered how companies handle mountains of data efficiently? Enter MapReduce—Hadoop’s superhero when it comes to processing large datasets. Instead of one machine trying to handle everything, MapReduce breaks the work into smaller chunks and distributes it across many machines, making the process faster and more reliable.","timestamp":"2024-09-28 21:50:56","image":"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fmap_reduce.webp?alt=media&token=9675cfce-94c9-4495-9f54-d6f651de19ff","image_alt":"Map reduce","slug":"mapreduce-the-magic-behind-processing-big-data-in-hadoop","index":"6b86b273ff34f","tags":["Data","Software Architecture","System Design","Storage"]}]},"__N_SSG":true}
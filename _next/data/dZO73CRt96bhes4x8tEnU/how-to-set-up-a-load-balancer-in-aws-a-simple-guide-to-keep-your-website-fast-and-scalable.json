{"pageProps":{"article":{"blog_id":"2b8dd94e-d12e-47ea-ba0b-dc2c18c37b68","title":"How to Set Up a Load Balancer in AWS: A Simple Guide to Keep Your Website Fast and Scalable","short_description":"You’ve built an amazing website or app, and the traffic starts pouring in. Users are clicking, scrolling, and browsing like never before. Everything is running smoothly… until it’s not. Suddenly, your server gets overwhelmed, and your site slows down. Worse, it crashes. Yikes!  What do you do?  Enter Load Balancing — your superhero in the world of web traffic. ?  But why do we need it, and how do we set it up on AWS using Nginx? Let's dive in and break it down in simple terms.","description":"<h1><strong>Why You Need Load Balancing</strong></h1><p>Imagine you’re throwing a huge party, and your house is the server. If everyone shows up at once, there’s no room to move, and things get crowded. But if you have a few people guiding guests into different rooms, everyone gets a chance to enjoy the party without overcrowding any single room. This is <strong>Load Balancing</strong>!</p><p>Load balancing is like your traffic manager: it takes the incoming website traffic and evenly distributes it across multiple servers. The result?</p><ul><li><strong>Better Performance</strong>: No server is overloaded.</li><li><strong>More Reliability</strong>: If one server crashes, the others keep the party going.</li><li><strong>Easy Scalability</strong>: As your site grows, you can add more servers to handle more traffic without a hitch.</li></ul><p>In this guide, we’re going to set up a simple load balancing system on AWS using <strong>EC2 instances</strong> and <strong>Nginx</strong> (a popular web server). We’ll skip the fancy AWS Elastic Load Balancer (ELB) for now and do it ourselves. ?</p><h1><strong>The Load Balancing Setup in a Nutshell</strong></h1><h1><img src=\"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fload_balancing_structure.png?alt=media&amp;token=92732226-d927-43d0-9d9e-3d82fed692f1\" alt=\"load balancing workflow example for demo\" width=\"720px\"></h1><p>In a typical web application, you want to ensure that traffic is efficiently managed across your infrastructure. If all users are directed to a single server, that server might get overloaded, causing slow response times or crashes. This is where <strong>load balancing</strong> comes into play.</p><p>Let’s break down our setup:</p><p><strong>- 1 Load Balancer</strong>: This is like the traffic cop for your web traffic. When users visit your website, their requests first hit the load balancer. The load balancer’s job is to direct these requests to the available backend servers.</p><p><strong>- 2 Server Instances</strong>: These are your backend servers that actually process the users’ requests and return content. The load balancer will send incoming requests to either Server 1 or Server 2, ensuring that no single server is overwhelmed. If one server goes down, the load balancer automatically redirects traffic to the other one, ensuring high availability.</p><h1><strong>What You’ll Need</strong></h1><p>Before we start, make sure you have:</p><p><strong>1. Three EC2 instances</strong> on AWS: One for the load balancer and two for the backend servers.</p><p><strong>2. Nginx installed</strong> on all the instances. It’ll handle the distribution of traffic to the backend servers.</p><h1><strong>Let’s Get Started! Step by Step</strong></h1><h3><strong>Step 1: Launch EC2 Instances in AWS</strong></h3><p>You’ll need three EC2 instances:</p><ul><li><strong>Server 1 (Backend)</strong>: This server will handle part of the traffic.</li><li><strong>Server 2 (Backend)</strong>: Another server to handle a different part of the traffic.</li><li><strong>Load Balancer</strong>: This instance will distribute the traffic between the two backend servers.</li></ul><p>All servers should be in the same <strong>VPC</strong> (Virtual Private Cloud) for easy communication.</p><h3><strong>Step 2: Install Nginx on Each EC2 Instance</strong></h3><p>Once your EC2 instances are running, it’s time to install Nginx. You can do that by connecting to each instance and running:</p><div><pre><code>sudo apt update \nsudo apt install nginx\n</code></pre></div><h3><strong>Step 3: Configure Nginx on the Load Balancer</strong></h3><p>Now comes the fun part — setting up Nginx on the <strong>Load Balancer</strong>.</p><p><strong>1. Access your load balancer instance</strong> and open the Nginx configuration file:</p><div><pre><code>sudo nano /etc/nginx/nginx.conf\n</code></pre></div><p><strong>2. Add the following configuration</strong> inside the http block:</p><div><pre><code>upstream backend_servers {\n&nbsp;&nbsp;server 172.31.27.145;&nbsp;# Private IP of Server 1\n&nbsp;&nbsp;server 172.31.27.91;&nbsp;&nbsp;# Private IP of Server 2\n}\n\nserver {\n&nbsp;&nbsp;listen 80;\n&nbsp;&nbsp;server_name &lt;load-balancer-public-IP&gt;;\n\n&nbsp;&nbsp;location / {\n&nbsp;&nbsp;&nbsp;&nbsp;proxy_pass http://backend_servers;\n&nbsp;&nbsp;}\n}\n</code></pre></div><p>This is telling Nginx, “Hey, I’ve got two backend servers here (with private IPs), and I want to send all incoming traffic to them.” The load balancer will automatically send traffic to either Server 1 or Server 2.</p><p><strong>Check if the configuration is correct</strong>:</p><div><pre><code>sudo nginx -t\n</code></pre></div><p><strong>Reload Nginx</strong> to apply the new settings:</p><div><pre><code>sudo systemctl reload nginx\n</code></pre></div><h3><strong>Step 4: Test Your Backend Servers</strong></h3><p>Before you test the load balancing, make sure both of your backend servers are working properly.</p><p><strong>- On Server 1</strong>, create a simple HTML file that says “Hello from Server 1”:</p><div><pre><code>sudo nano /usr/share/nginx/html/index.html\n</code></pre></div><p><strong>- Write: Hello from Server 2 n the file.</strong></p><p><strong>- On Server 2, do the same but say “Hello from Server 2”.</strong></p><p><strong>- Test each server directly:</strong></p><p>From your load balancer instance, you can use curl to check if each server is serving the correct page:</p><div><pre><code>curl http://172.31.27.145  # Server 1\ncurl http://172.31.27.91   # Server 2\n</code></pre></div><p>You should see “Hello from Server 1” for Server 1 and “Hello from Server 2” for Server 2.</p><h3><strong>Step 5: Test the Load Balancer</strong></h3><p>Now, let’s put the load balancing to the test. Open your browser and go to the <strong>public IP</strong> of the <strong>Load Balancer</strong>.</p><p>When you hit the load balancer’s IP:</p><ul><li>It should alternate between “Hello from Server 1” and “Hello from Server 2” as Nginx sends traffic to each backend server in turn.</li></ul><h1><strong>Conclusion: You Did It!</strong></h1><p>Congratulations! ? You’ve just set up a basic load balancing system using Nginx on AWS EC2 instances. By distributing traffic across multiple servers, you’ve made your web app faster, more reliable, and more scalable.</p><p>This is just the beginning — you can easily expand this setup by adding more backend servers or even implementing more advanced load balancing techniques.</p><h1><strong>What's Next?</strong></h1><p><strong>1. Add More Servers</strong>: Scale up by adding more backend servers to handle more traffic.</p><p><strong>2. Secure Your Setup</strong>: Set up SSL certificates to encrypt traffic.</p><p><strong>3. Monitor Your Servers</strong>: Use AWS CloudWatch or Nginx logs to monitor the performance of your servers and load balancer.</p><p>Now that you understand how load balancing works, you can implement it in your projects to keep your websites and applications fast and responsive, no matter how much traffic you get! ??</p>","timestamp":"Thursday, December 12, 2024 at 12:48:36 PM GMT+8","image":"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fload_balancing_background.jpg?alt=media&token=a5b062fc-45ad-4770-be8f-ff5b7097c6cc","image_alt":"Load Balancing Background Lab","slug":"how-to-set-up-a-load-balancer-in-aws-a-simple-guide-to-keep-your-website-fast-and-scalable","index":"6b86b273ff34f","tags":["Software Architecture","System Design"]},"recommendedPosts":[{"blog_id":"4400b3a0-4d34-4185-806a-f265089e8af8","title":"MySQL Migration with Connection Pooling: A Simple Guide","short_description":"Imagine standing in line at a coffee shop where each customer needs to fill out a membership form before ordering and then tears it up after getting their coffee. Sounds inefficient, right? This is exactly what happens when your application connects to a database without connection pooling.","timestamp":"2025-04-28 11:49:06","image":"https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1745838714722_connection%20pool%20Bg.png","image_alt":"Connection Pool Labs Content","slug":"MySQL-Migration-with-Connection-Pooling-A-Simple-Guide-1","index":"d4735e3a265e1","tags":["System Design","Database","Software Architecture","Cloud Computing"]},{"blog_id":"6234fef8-1547-46f7-ae10-33d577a1d168","title":"Understanding RabbitMQ: A Favorite Simple Messaging Service!","short_description":"RabbitMQ is a robust, open-source message broker that facilitates communication between applications by sending and receiving messages. Whether you're building a microservices architecture or a distributed system, RabbitMQ ensures reliable, scalable, and asynchronous messaging. In this blog, we’ll walk through its core components and concepts, from producers to consumers, and dive into some advanced features like round-robin dispatching and virtual hosts.","timestamp":"2025-03-15 19:44:13","image":"https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1742090540692_rabbitmq.webp","image_alt":"rabbit mq","slug":"Understanding-RabbitMQ-A-Favorite-Simple-Messaging-Service","index":"6b86b273ff34f","tags":["Message Broker","System Design","Software Architecture"]},{"blog_id":"86f7440f-033f-4459-b0a5-09f74d7c34ba","title":"Understanding Circuit Breakers in Software Engineering: From Traditional to Serverless","short_description":"Imagine you’re using electricity at home, and a short circuit occurs. The circuit breaker in your electrical panel cuts the power to prevent a fire. In software, the concept is similar: it’s a design pattern that protects your system from repeated failures when calling external services","timestamp":"2025-03-14 02:46:27","image":"https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1741948558177_circuit_breaker.png","image_alt":"Circuit breaker","slug":"Understanding-Circuit-Breakers-in-Software-Engineering-From-Traditional-to-Serverless","index":"6b86b273ff34f","tags":["System Design","Software Architecture"]}]},"__N_SSG":true}